# Put your `run_remote.sh` configs in this YAML file
training:
    learning_rate: 0.0005
    scheduler: poly # constant
    warmup_steps: 20000
    num_epochs: 500
    batch_size: 1024
    eval_batch_size: 1024
    log_per_step: 20
    sigma_min: 0.0
    wandb: True
    checkpoint_per_epoch: 1000
    eval_per_epoch: 5
    # load_from: /kmh-nfs-us-mount/logs/sqa/sqa_NCSNv2/20241101_030317_2ml2nf_kmh-tpuvm-v2-32-1__b_lr_ep_torchvision_r50_eval/checkpoint_5684
model:
    name: UNet_for_mnist
dataset:
    name: MNIST
    root: /kmh-nfs-ssd-eu-mount/code/qiao/data/MNIST/
    image_size: 28
    prefetch_factor: 2
    num_workers: 64 # NOTE: On V2, if you don't use num_workers=64, sometimes the code will exit unexpectedly
sampling:
    ema: True
    ema_decay: 0.999
    save_dir: null
fid:
    eval_only: True
    fid_per_epoch: 10

# NOTE: you cannot add more hierarchy structure without modifying default.py and load_config.py